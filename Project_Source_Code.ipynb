{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "998d6170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter primary key(s), separated by commas: OrderID, CustomerID, DrinkID, FoodID\n",
      "Provide Functional Dependencies in the format 'A,B -> C,D' (type 'done' when finished):\n",
      "OrderID -> CustomerID\n",
      "done\n",
      "Select the highest normal form to achieve (1: 1NF, 2: 2NF, 3: 3NF, B: BCNF, 4: 4NF, 5: 5NF): 4\n",
      "Provide Multi-Valued Dependencies in the format 'A ->> B' (type 'done' when finished):\n",
      "OrderID ->> DrinkID\n",
      "done\n",
      "CREATE TABLE Table_1NF (\n",
      "  OrderID INT,\n",
      "  Date VARCHAR(255),\n",
      "  PromocodeUsed VARCHAR(255),\n",
      "  TotalCost VARCHAR(255),\n",
      "  TotalDrinkCost VARCHAR(255),\n",
      "  TotalFoodCost VARCHAR(255),\n",
      "  CustomerID INT,\n",
      "  CustomerName VARCHAR(255),\n",
      "  DrinkID INT,\n",
      "  DrinkName VARCHAR(255),\n",
      "  DrinkSize VARCHAR(255),\n",
      "  DrinkQuantity INT,\n",
      "  Milk VARCHAR(255),\n",
      "  DrinkIngredient VARCHAR(255),\n",
      "  DrinkAllergen VARCHAR(255),\n",
      "  FoodID INT,\n",
      "  FoodName VARCHAR(255),\n",
      "  FoodQuantity INT,\n",
      "  FoodIngredient VARCHAR(255),\n",
      "  FoodAllergen VARCHAR(255),\n",
      "  PRIMARY KEY (OrderID, CustomerID, DrinkID, FoodID)\n",
      ");\n",
      "CREATE TABLE Table_4NF_1 (\n",
      "  OrderID INT,\n",
      "  Date VARCHAR(255),\n",
      "  PromocodeUsed VARCHAR(255),\n",
      "  TotalCost VARCHAR(255),\n",
      "  TotalDrinkCost VARCHAR(255),\n",
      "  TotalFoodCost VARCHAR(255),\n",
      "  CustomerID INT,\n",
      "  CustomerName VARCHAR(255),\n",
      "  DrinkName VARCHAR(255),\n",
      "  DrinkSize VARCHAR(255),\n",
      "  DrinkQuantity INT,\n",
      "  Milk VARCHAR(255),\n",
      "  DrinkIngredient VARCHAR(255),\n",
      "  DrinkAllergen VARCHAR(255),\n",
      "  FoodID INT,\n",
      "  FoodName VARCHAR(255),\n",
      "  FoodQuantity INT,\n",
      "  FoodIngredient VARCHAR(255),\n",
      "  FoodAllergen VARCHAR(255),\n",
      "  PRIMARY KEY (OrderID, CustomerID, DrinkID, FoodID)\n",
      ");\n",
      "CREATE TABLE Table_4NF_2 (\n",
      "  OrderID INT,\n",
      "  DrinkID INT,\n",
      "  PRIMARY KEY (OrderID, DrinkID)\n",
      ");\n",
      "Normalization results saved to C:/Users/saiki/OneDrive/Desktop/normalization_output1.txt\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "\n",
    "# Load the input file\n",
    "data_file_path = 'C:/Users/saiki/OneDrive/Desktop/Sampledata.csv'\n",
    "data = pd.read_csv(data_file_path, encoding='ISO-8859-1')\n",
    "\n",
    "# Define the output file path\n",
    "output_file_path = 'C:/Users/saiki/OneDrive/Desktop/normalization_output1.txt'\n",
    "with open(output_file_path, 'w') as output_file:\n",
    "\n",
    "    # Prompt for primary keys\n",
    "    primary_keys = input(\"Enter primary key(s), separated by commas: \").split(',')\n",
    "    primary_keys = [key.strip() for key in primary_keys]\n",
    "\n",
    "    # Prompt for functional dependencies\n",
    "    functional_dependencies = {}\n",
    "    print(\"Provide Functional Dependencies in the format 'A,B -> C,D' (type 'done' when finished):\")\n",
    "    while True:\n",
    "        fd_input = input()\n",
    "        if fd_input.lower() == 'done':\n",
    "            break\n",
    "        try:\n",
    "            determinant, dependent = fd_input.split(\"->\")\n",
    "            determinant_attrs = [attr.strip() for attr in determinant.split(',')]\n",
    "            dependent_attrs = [attr.strip() for attr in dependent.split(',')]\n",
    "            functional_dependencies[tuple(determinant_attrs)] = dependent_attrs\n",
    "            output_file.write(f\"Functional Dependency: {determinant} -> {dependent}\\n\")\n",
    "        except ValueError:\n",
    "            print(\"Invalid format. Please use 'A,B -> C,D'.\")\n",
    "\n",
    "    # Get the highest normal form to achieve\n",
    "    highest_form = input(\"Select the highest normal form to achieve (1: 1NF, 2: 2NF, 3: 3NF, B: BCNF, 4: 4NF, 5: 5NF): \")\n",
    "    if highest_form in [\"1\", \"2\", \"3\", \"4\", \"5\"]:\n",
    "        highest_form = int(highest_form)\n",
    "\n",
    "    # Prompt for multi-valued dependencies if the target form is 4NF or higher\n",
    "    multi_valued_dependencies = {}\n",
    "    if highest_form >= 4:\n",
    "        print(\"Provide Multi-Valued Dependencies in the format 'A ->> B' (type 'done' when finished):\")\n",
    "        while True:\n",
    "            mvd_input = input()\n",
    "            if mvd_input.lower() == 'done':\n",
    "                break\n",
    "            try:\n",
    "                determinant, dependent = mvd_input.split(\"->>\")\n",
    "                determinant = determinant.strip()\n",
    "                dependent = dependent.strip()\n",
    "                if determinant in multi_valued_dependencies:\n",
    "                    multi_valued_dependencies[determinant].append(dependent)\n",
    "                else:\n",
    "                    multi_valued_dependencies[determinant] = [dependent]\n",
    "                output_file.write(f\"Multi-Valued Dependency: {determinant} ->> {dependent}\\n\")\n",
    "            except ValueError:\n",
    "                print(\"Invalid format. Please use 'A ->> B'.\")\n",
    "\n",
    "    # Prompt for join dependencies if the target form is 5NF\n",
    "    join_dependencies = []\n",
    "    if highest_form == 5:\n",
    "        print(\"Provide Join Dependencies in the format 'A,B' (type 'done' when finished):\")\n",
    "        while True:\n",
    "            jd_input = input()\n",
    "            if jd_input.lower() == 'done':\n",
    "                break\n",
    "            jd_attrs = [attr.strip() for attr in jd_input.split(',')]\n",
    "            join_dependencies.append(jd_attrs)\n",
    "            output_file.write(f\"Join Dependency: {', '.join(jd_attrs)}\\n\")\n",
    "\n",
    "    # Function to ensure 1NF by handling non-atomic columns\n",
    "    def apply_1nf(df):\n",
    "        non_atomic_cols = []\n",
    "        for col in df.columns:\n",
    "            if df[col].apply(lambda x: isinstance(x, list)).any():\n",
    "                non_atomic_cols.append(col)\n",
    "                df = df.explode(col)\n",
    "        return df, non_atomic_cols\n",
    "\n",
    "    # Function to check 2NF\n",
    "    def validate_2nf(df, primary_keys, dependencies):\n",
    "        non_prime_columns = [col for col in df.columns if col not in primary_keys]\n",
    "        for det, dep in dependencies.items():\n",
    "            if set(det).issubset(primary_keys) and any(attr in non_prime_columns for attr in dep):\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    # Function to check 3NF\n",
    "    def validate_3nf(df, primary_keys, dependencies):\n",
    "        for det, dep in dependencies.items():\n",
    "            if set(det) != set(primary_keys) and not set(dep).issubset(primary_keys):\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    # Function to check BCNF\n",
    "    def validate_bcnf(df, primary_keys, dependencies):\n",
    "        for det, dep in dependencies.items():\n",
    "            if not set(det).issubset(primary_keys):\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    # Function to apply 4NF using multi-valued dependencies\n",
    "    def apply_4nf(df, mv_dependencies):\n",
    "        decomposed_tables = []\n",
    "        remaining_columns = list(df.columns)\n",
    "\n",
    "        for det, dep_list in mv_dependencies.items():\n",
    "            for dep in dep_list:\n",
    "                decomposed_table = df[[det, dep]].drop_duplicates()\n",
    "                decomposed_tables.append((decomposed_table, [det, dep]))  # Track primary key for decomposed table\n",
    "                if dep in remaining_columns:\n",
    "                    remaining_columns.remove(dep)\n",
    "                output_file.write(f\"4NF Decomposition: Created table with {det} ->> {dep}\\n\")\n",
    "\n",
    "        main_table = df[remaining_columns].drop_duplicates()\n",
    "        return [(main_table, primary_keys)] + decomposed_tables\n",
    "\n",
    "    # Function to apply 5NF using join dependencies\n",
    "    def apply_5nf(df, join_deps):\n",
    "        decomposed_tables = []\n",
    "\n",
    "        for jd in join_deps:\n",
    "            if set(jd).issubset(df.columns):\n",
    "                decomposed_table = df[jd].drop_duplicates()\n",
    "                decomposed_tables.append((decomposed_table, jd))\n",
    "                output_file.write(f\"5NF Decomposition: Created table for JD ({', '.join(jd)})\\n\")\n",
    "\n",
    "        if not decomposed_tables:\n",
    "            output_file.write(\"No further 5NF decomposition required.\\n\")\n",
    "        return [(df, primary_keys)] + decomposed_tables\n",
    "\n",
    "    # SQL Query Generator and Schema Representation\n",
    "    def generate_sql_schema(table_name, df, primary_keys):\n",
    "        sql_query = f\"CREATE TABLE {table_name} (\\n\"\n",
    "        schema_info = f\"Table: {table_name}\\nAttributes:\\n\"\n",
    "\n",
    "        for col, dtype in zip(df.columns, df.dtypes):\n",
    "            col_type = 'INT' if 'int' in str(dtype) else 'VARCHAR(255)'\n",
    "            sql_query += f\"  {col} {col_type},\\n\"\n",
    "            schema_info += f\"  - {col} ({col_type})\\n\"\n",
    "\n",
    "        primary_key_str = \", \".join(primary_keys)\n",
    "        sql_query += f\"  PRIMARY KEY ({primary_key_str})\\n);\"\n",
    "        schema_info += f\"Primary Key(s): {primary_key_str}\\n\\n\"\n",
    "\n",
    "        print(sql_query)\n",
    "        output_file.write(sql_query + \"\\n\\n\" + schema_info)\n",
    "\n",
    "    # Main Normalization Process\n",
    "    def normalize_data(df, primary_keys, fds, mvds, highest_form, jds=[]):\n",
    "        df, non_atomic_cols = apply_1nf(df)\n",
    "        output_file.write(\"Applied 1NF\\n\" if not non_atomic_cols else f\"1NF: Converted non-atomic columns {non_atomic_cols}\\n\")\n",
    "        generate_sql_schema('Table_1NF', df, primary_keys)\n",
    "\n",
    "        current_nf = 1\n",
    "        if highest_form >= 2 and validate_2nf(df, primary_keys, fds):\n",
    "            output_file.write(\"2NF validation successful.\\n\")\n",
    "            current_nf = 2\n",
    "        else:\n",
    "            output_file.write(\"2NF decomposition needed.\\n\")\n",
    "\n",
    "        if highest_form >= 3 and validate_3nf(df, primary_keys, fds):\n",
    "            output_file.write(\"3NF validation successful.\\n\")\n",
    "            current_nf = 3\n",
    "        else:\n",
    "            output_file.write(\"3NF decomposition needed.\\n\")\n",
    "\n",
    "        if highest_form >= 4 and validate_bcnf(df, primary_keys, fds):\n",
    "            output_file.write(\"BCNF validation successful.\\n\")\n",
    "            current_nf = \"BCNF\"\n",
    "        else:\n",
    "            output_file.write(\"BCNF decomposition needed.\\n\")\n",
    "\n",
    "        decomposed_tables = [(df, primary_keys)]\n",
    "        if highest_form >= 4:\n",
    "            decomposed_tables = apply_4nf(df, mvds)\n",
    "            for i, (table, keys) in enumerate(decomposed_tables, start=1):\n",
    "                table_name = f\"Table_4NF_{i}\"\n",
    "                generate_sql_schema(table_name, table, keys)\n",
    "            current_nf = 4 if current_nf != \"BCNF\" else current_nf\n",
    "\n",
    "        if highest_form == 5:\n",
    "            decomposed_tables = apply_5nf(df, jds)\n",
    "            for i, (table, keys) in enumerate(decomposed_tables, start=1):\n",
    "                table_name = f\"Table_5NF_{i}\"\n",
    "                generate_sql_schema(table_name, table, keys)\n",
    "\n",
    "        output_file.write(f\"The highest normal form achieved: {current_nf}\\n\")\n",
    "\n",
    "    # Execute the normalization\n",
    "    normalize_data(data, primary_keys, functional_dependencies, multi_valued_dependencies, highest_form, join_dependencies)\n",
    "\n",
    "print(f\"Normalization results saved to {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdb4412",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
